{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading needed methods\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "from random import seed,sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_curve, auc,\\\n",
    "precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# loading data\n",
    "\n",
    "data = pd.read_csv(\"/Users/cosmos/Documents/AIML Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting data according to the conclusion above\n",
    "# I don't have to subset for the fraud dataset because all of their transaction types are either TRANSFER or CASH_OUT\n",
    "\n",
    "data_new = data.copy() \n",
    "\n",
    "# filling feature column\n",
    "data_new.loc[data.nameOrig.str.contains('C') & data.nameDest.str.contains('C'),\"type1\"] = \"CC\" \n",
    "data_new.loc[data.nameOrig.str.contains('C') & data.nameDest.str.contains('M'),\"type1\"] = \"CM\"\n",
    "data_new.loc[data.nameOrig.str.contains('M') & data.nameDest.str.contains('C'),\"type1\"] = \"MC\"\n",
    "data_new.loc[data.nameOrig.str.contains('M') & data.nameDest.str.contains('M'),\"type1\"] = \"MM\"\n",
    "\n",
    "\n",
    "\n",
    "fraud = data_new[data_new[\"isFraud\"] == 1]\n",
    "valid = data_new[data_new[\"isFraud\"] == 0]\n",
    "\n",
    "\n",
    "\n",
    "fraud = fraud.drop('type1', 1)\n",
    "valid = valid.drop('type1',1)\n",
    "data_new = data_new.drop('type1',1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# valid = valid[(valid[\"type\"] == \"CASH_OUT\")| (valid[\"type\"] == \"TRANSFER\")]\n",
    "# data_new = data_new[(data_new[\"type\"] == \"CASH_OUT\") | (data_new[\"type\"] == \"TRANSFER\")]\n",
    "\n",
    "wrong_orig_bal = sum(data[\"oldbalanceOrg\"] - data[\"amount\"] != data[\"newbalanceOrig\"])\n",
    "wrong_dest_bal = sum(data[\"newbalanceDest\"] + data[\"amount\"] != data[\"newbalanceDest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations with negative numbers:  0\n",
      "number of observations where the amount given is greater than the amount that is in the giver's account:  4079080\n",
      "number of observations where the amount received is greater than the amount that is in the receiver's account:  2661141\n"
     ]
    }
   ],
   "source": [
    "## Calculating some quantities to justify or reject some assumptions\n",
    "\n",
    "# flatten the subsetted dataframe of floats into an array of floats\n",
    "relevant_cols = data[[\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\"]].values.flatten()\n",
    "# number of observations with negative numbers\n",
    "num_neg_amt = sum(n < 0 for n in relevant_cols)\n",
    "# number of observations where the amount given is greater than the amount that is in the giver's account\n",
    "num_amt_oldgiver = sum(data[\"amount\"] > data[\"oldbalanceOrg\"]) \n",
    "# number of observations where the amount received is greater than the amount that is in the receiver's account\n",
    "num_amt_newreceiver = sum(data[\"amount\"] > data[\"newbalanceDest\"]) \n",
    "\n",
    "print(\"number of observations with negative numbers: \", num_neg_amt)\n",
    "print(\"number of observations where the amount given is greater than the amount that is in the giver's account: \"\n",
    "      , num_amt_oldgiver)\n",
    "print(\"number of observations where the amount received is greater than the amount that is in the receiver's account: \"\n",
    "      , num_amt_newreceiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wrong_bal = (data[\"oldbalanceOrg\"] - data[\"amount\"] != data[\"newbalanceOrig\"]) | (data[\"newbalanceDest\"] + data[\"amount\"] != data[\"newbalanceDest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding features errorBalanceOrg, errorBalanceDest\n",
    "data_new[\"errorBalanceOrg\"] = data_new.newbalanceOrig + data_new.amount - data_new.oldbalanceOrg\n",
    "data_new[\"errorBalanceDest\"] = data_new.oldbalanceDest + data_new.amount - data_new.newbalanceDest\n",
    "\n",
    "# Subsetting data into observations with fraud and valid transactions:\n",
    "fraud = data_new[data_new[\"isFraud\"] == 1]\n",
    "valid = data_new[data_new[\"isFraud\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating transfers and cashouts for fraud accounts\n",
    "\n",
    "fraud_transfer = fraud[fraud[\"type\"] == \"TRANSFER\"]\n",
    "fraud_cashout = fraud[fraud[\"type\"] == \"CASH_OUT\"]\n",
    "\n",
    "# checking if the recipient account of a fraudulent transfer was used as a sending account for cashing out \n",
    "fraud_transfer.nameDest.isin(fraud_cashout.nameOrig).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of nameDest column.\n",
    "# names = [\"nameDest\"]\n",
    "# fraud = fraud.drop(names, 1)\n",
    "# valid = valid.drop(names,1)\n",
    "# data_new = data_new.drop(names,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16  observations were flagged correctly and  0  observations were flagged wrongly for a total of  16  flagged observations.\n",
      "number of observations that should be flagged:  2740\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flagged = data_new[data_new[\"isFlaggedFraud\"] == 1]\n",
    "flagged_correctly = sum(flagged[\"isFraud\"] == 1)\n",
    "flagged_wrongly = len(flagged) - flagged_correctly\n",
    "total = flagged_correctly + flagged_wrongly\n",
    "print(flagged_correctly,\" observations were flagged correctly and \", flagged_wrongly, \\\n",
    "      \" observations were flagged wrongly for a total of \", total, \" flagged observations.\")\n",
    "\n",
    "# how many observations where the transaction is fraudulent, the transaction is a transfer and the amount is greater \n",
    "# than 200, 000 are in the dataset\n",
    "should_be_flagged = fraud[(fraud[\"amount\"] > 200000) & (fraud[\"type\"] == \"TRANSFER\")]\n",
    "print(\"number of observations that should be flagged: \",len(should_be_flagged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droppin is flagged fraud\n",
    "# fraud = fraud.drop(\"isFlaggedFraud\",1)\n",
    "# valid = valid.drop(\"isFlaggedFraud\",1)\n",
    "# data_new = data_new.drop(\"isFlaggedFraud\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = data_new.copy()\n",
    "\n",
    "\n",
    "# adding feature HourOfDay to Dataset1 \n",
    "dataset1[\"HourOfDay\"] = np.nan # initializing feature column\n",
    "dataset1.HourOfDay = data_new.step % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset1.copy() # unchanged dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.get_dummies(dataset,prefix=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>errorBalanceOrg</th>\n",
       "      <th>errorBalanceDest</th>\n",
       "      <th>HourOfDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type   amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT  9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT  1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER   181.00  C1305486145          181.0            0.00   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0  M1979787155             0.0             0.0        0               0   \n",
       "1  M2044282225             0.0             0.0        0               0   \n",
       "2   C553264065             0.0             0.0        1               0   \n",
       "\n",
       "   errorBalanceOrg  errorBalanceDest  HourOfDay  \n",
       "0              0.0           9839.64          1  \n",
       "1              0.0           1864.28          1  \n",
       "2              0.0            181.00          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.to_csv('/Users/cosmos/Desktop/final-db-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\"\\'isFlaggedFraud\\'\"] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2h/lw5rv90j0ln7v084d1vkrcg80000gn/T/ipykernel_2237/2175516151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Not that the actual number doesn't matter and is only used to make sure results are reproducible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# creating training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"isFraud\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"nameOrig\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"nameDest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"'isFlaggedFraud'\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misFraud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m         \"\"\"\n\u001b[0;32m-> 4308\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4153\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4188\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5591\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5592\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5593\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5594\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[\"\\'isFlaggedFraud\\'\"] not found in axis'"
     ]
    }
   ],
   "source": [
    "RandomState = 42\n",
    "seed(21)\n",
    "\n",
    "\n",
    "# 42 is used often due to Hitchhiker's Guide to the Galaxy, I will use a number that a far smaller group may understand.\n",
    "# Not that the actual number doesn't matter and is only used to make sure results are reproducible.\n",
    "# creating training and testing sets\n",
    "X = dataset.drop(columns=[\"isFraud\",\"type\",\"nameOrig\",\"nameDest\",\"'isFlaggedFraud'\"],axis=1)\n",
    "y = dataset.isFraud\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "# Normalizing data so that all variables follow the same scale (0 to 1)\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit only to the training data\n",
    "# scaler.fit(X_train)\n",
    "\n",
    "# # Now apply the transformations to the data:\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest', 'isFlaggedFraud', 'errorBalanceOrg',\n",
       "       'errorBalanceDest', 'HourOfDay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:56:49] WARNING: /private/var/folders/2h/lw5rv90j0ln7v084d1vkrcg80000gn/T/pip-install-l80c8wob/xgboost_fef350fccbfe489b99be0e26506efa00/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# Trainning model\n",
    "\n",
    "weights = (y == 0).sum() / (1.0 * (y == 1).sum()) # for unbalanced datasets, these weights are recommended\n",
    "parametersXGB = {'max_depth':3,'scale_pos_weight': weights,'n_jobs':-1,\\\n",
    "                 'random_state':RandomState,'learning_rate':0.1}\n",
    "XGB = XGBClassifier(**parametersXGB)\n",
    "    \n",
    "fitted_vals = XGB.fit(X_train, y_train)\n",
    " \n",
    "# Predict on testing set\n",
    "predictionsXGB = XGB.predict(X_test)\n",
    " \n",
    "     \n",
    "# Evaluating model\n",
    "CM_XGB = confusion_matrix(y_test,predictionsXGB)\n",
    "CR_XGB = classification_report(y_test,predictionsXGB)\n",
    "fprXGB, recallXGB, thresholds_XGB = roc_curve(y_test, predictionsXGB)\n",
    "AUC_XGB = auc(fprXGB, recallXGB)\n",
    "resultsXGB = {\"Confusion Matrix\":CM_XGB,\"Classification Report\":CR_XGB,\"Area Under Curve\":AUC_XGB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xgb_prediction1, open('xgboost-without-type.sav','wb'))\n",
    "#loaded_model = pickle.load(open('/Users/cosmos/Desktop/I-ll_think_about_it_later/models/xgboost-full.sav', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
